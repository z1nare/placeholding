{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Loss: 1.0860 - Train Acc: 37.11% - Val Acc: 51.19%\n",
      "Epoch 2/15 - Loss: 0.8570 - Train Acc: 60.99% - Val Acc: 80.00%\n",
      "Epoch 3/15 - Loss: 0.4357 - Train Acc: 83.23% - Val Acc: 91.90%\n",
      "Epoch 4/15 - Loss: 0.2570 - Train Acc: 91.66% - Val Acc: 94.17%\n",
      "Epoch 5/15 - Loss: 0.1916 - Train Acc: 93.45% - Val Acc: 94.05%\n",
      "Epoch 6/15 - Loss: 0.1495 - Train Acc: 94.88% - Val Acc: 92.62%\n",
      "Epoch 7/15 - Loss: 0.1393 - Train Acc: 95.29% - Val Acc: 95.24%\n",
      "Epoch 8/15 - Loss: 0.1067 - Train Acc: 96.81% - Val Acc: 91.90%\n",
      "Epoch 9/15 - Loss: 0.1145 - Train Acc: 96.66% - Val Acc: 92.86%\n",
      "Epoch 10/15 - Loss: 0.0878 - Train Acc: 97.38% - Val Acc: 93.10%\n",
      "Epoch 11/15 - Loss: 0.0838 - Train Acc: 97.53% - Val Acc: 97.86%\n",
      "Epoch 12/15 - Loss: 0.0692 - Train Acc: 97.92% - Val Acc: 97.50%\n",
      "Epoch 13/15 - Loss: 0.0646 - Train Acc: 98.24% - Val Acc: 97.86%\n",
      "Epoch 14/15 - Loss: 0.0657 - Train Acc: 98.03% - Val Acc: 98.21%\n",
      "Epoch 15/15 - Loss: 0.0647 - Train Acc: 98.15% - Val Acc: 98.33%\n",
      "✅ Model saved to spectrogram_classifier.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===============================\n",
    "# 1. Custom Dataset\n",
    "# ===============================\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))  # ['bird', 'cat', 'dog']\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        self.transform = transform\n",
    "\n",
    "        for label in self.classes:\n",
    "            csv_files = glob.glob(os.path.join(root_dir, label, \"*.csv\"))\n",
    "            for f in csv_files:\n",
    "                self.samples.append(f)\n",
    "                self.labels.append(self.class_to_idx[label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.samples[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load spectrogram from CSV\n",
    "        spec = pd.read_csv(path, header=None).values.astype(np.float32)\n",
    "\n",
    "        # Normalize to 0..1\n",
    "        spec = (spec - spec.min()) / (spec.max() - spec.min() + 1e-8)\n",
    "\n",
    "        # Add channel dimension for CNN: [1, H, W]\n",
    "        spec = torch.tensor(spec).unsqueeze(0)\n",
    "\n",
    "        return spec, label\n",
    "\n",
    "# ===============================\n",
    "# 2. Simple CNN model\n",
    "# ===============================\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((4,4))  # compress to fixed size\n",
    "        )\n",
    "        self.fc = nn.Linear(64*4*4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ===============================\n",
    "# 3. Training & Evaluation Loop\n",
    "# ===============================\n",
    "def train_model(data_root, epochs=10, batch_size=16, lr=1e-3):\n",
    "    # Dataset split\n",
    "    dataset = SpectrogramDataset(data_root)\n",
    "    train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, stratify=dataset.labels, random_state=42)\n",
    "\n",
    "    train_set = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_set = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "    # Model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = CNNClassifier(num_classes=len(dataset.classes)).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, pred = out.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                _, pred = out.max(1)\n",
    "                val_total += y.size(0)\n",
    "                val_correct += pred.eq(y).sum().item()\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {train_loss/len(train_loader):.4f} - Train Acc: {acc:.2f}% - Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    return model, dataset.classes\n",
    "\n",
    "# ===============================\n",
    "# 4. Run training\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    data_root = r\"\\processed_data\"\n",
    "    model, classes = train_model(data_root, epochs=15, batch_size=32, lr=1e-3)\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\"model\": model.state_dict(), \"classes\": classes}, \"spectrogram_classifier.pth\")\n",
    "    print(\"✅ Model saved to spectrogram_classifier.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
